{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from mavd.data_generator import DataGenerator\n",
    "from mavd.model import *\n",
    "from mavd.callbacks import *\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.models import Model\n",
    "from keras.layers import Concatenate,Dropout\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files parameters\n",
    "Nfiles = None\n",
    "resume = False\n",
    "load_subset = Nfiles\n",
    "\n",
    "# audio parameters\n",
    "sr = 22050\n",
    "sequence_time = 1.0\n",
    "sequence_hop_time = 0.5\n",
    "audio_hop = 512\n",
    "audio_win = 1024\n",
    "n_fft = 1024\n",
    "normalize_data = 'none' # para comparar loss con MST\n",
    "get_annotations = True\n",
    "mel_bands = 128\n",
    "htk = True\n",
    "normalize_energy = True\n",
    "\n",
    "# training\n",
    "learning_rate = 0.001\n",
    "epochs = 101\n",
    "batch_size = 64\n",
    "sed_early_stopping = 100\n",
    "epoch_limit = None\n",
    "fit_verbose = True\n",
    "fine_tuning = False\n",
    "\n",
    "#model\n",
    "large_cnn = True\n",
    "frames = True\n",
    "\n",
    "class_list1 = ['car','bus','motorcycle']\n",
    "class_list2 = ['engine','brakes','wheel','compressor']\n",
    "class_list3 = ['car/engine','car/wheel',\n",
    "              'bus/engine', 'bus/brakes','bus/compressor','bus/wheel',\n",
    "              'motorcycle/engine', 'motorcycle/brakes'] \n",
    "\n",
    "label_list = [class_list1,class_list2,class_list3]\n",
    "\n",
    "# Create output folders\n",
    "expfolder = '../exps/S-CNN_fine_tuning/'\n",
    "\n",
    "audio_folder = '/data_ssd/users/pzinemanas/MAVD-traffic/audio22050'\n",
    "label_folder='/data_ssd/users/pzinemanas/MAVD-traffic/annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Founding scaler\n",
      "Making generators\n",
      "Getting data\n",
      "(26356, 128)\n",
      "(615648, 128)\n",
      "train (13992, 44, 128)\n",
      "val (1995, 44, 128)\n",
      "\n",
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0830 13:36:16.218409 139915274192640 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0830 13:36:16.226257 139915274192640 deprecation.py:323] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 44, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 44, 128)           512       \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 44, 128, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 40, 124, 128)      3328      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 20, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 20, 62, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 58, 128)       409728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 29, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 29, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 25, 128)        409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 4, 25, 128)        512       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 3)                 99        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 8)                 40        \n",
      "=================================================================\n",
      "Total params: 2,484,155\n",
      "Trainable params: 4,283\n",
      "Non-trainable params: 2,479,872\n",
      "_________________________________________________________________\n",
      "\n",
      "Fitting model...\n",
      "Epoch 1/101\n",
      "13992/13992 [==============================] - 4s 284us/step - loss: 2.4503 - dense_26_loss: 0.9376 - dense_27_loss: 0.7240 - dense_28_loss: 0.7887\n",
      "F1 = 0.5383, ER = 0.5423, F1 = 0.3757, ER = 0.8757, F1 = 0.0926, ER = 3.0610 -  Best val F1s: 0.3355 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 2/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 2.1529 - dense_26_loss: 0.6883 - dense_27_loss: 0.7023 - dense_28_loss: 0.7623\n",
      "F1 = 0.4930, ER = 0.6430, F1 = 0.5051, ER = 0.8985, F1 = 0.0936, ER = 2.8100 -  Best val F1s: 0.3639 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 3/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 2.0503 - dense_26_loss: 0.6242 - dense_27_loss: 0.6885 - dense_28_loss: 0.7376\n",
      "F1 = 0.5001, ER = 0.6386, F1 = 0.5299, ER = 0.8834, F1 = 0.1456, ER = 2.9212 -  Best val F1s: 0.3919 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 4/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.9835 - dense_26_loss: 0.5924 - dense_27_loss: 0.6770 - dense_28_loss: 0.7141\n",
      "F1 = 0.4526, ER = 0.6885, F1 = 0.5469, ER = 0.8715, F1 = 0.1877, ER = 2.9502 -  Best val F1s: 0.3957 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 5/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.9301 - dense_26_loss: 0.5730 - dense_27_loss: 0.6655 - dense_28_loss: 0.6916\n",
      "F1 = 0.4842, ER = 0.6568, F1 = 0.5442, ER = 0.8834, F1 = 0.2326, ER = 2.8988 -  Best val F1s: 0.4203 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 6/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.8775 - dense_26_loss: 0.5531 - dense_27_loss: 0.6544 - dense_28_loss: 0.6700\n",
      "F1 = 0.5125, ER = 0.6260, F1 = 0.5442, ER = 0.9070, F1 = 0.3368, ER = 2.2942 -  Best val F1s: 0.4645 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 7/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.8357 - dense_26_loss: 0.5421 - dense_27_loss: 0.6439 - dense_28_loss: 0.6496\n",
      "F1 = 0.5196, ER = 0.6200, F1 = 0.5545, ER = 0.9135, F1 = 0.3382, ER = 2.2968 -  Best val F1s: 0.4708 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 8/101\n",
      "13992/13992 [==============================] - 2s 157us/step - loss: 1.7962 - dense_26_loss: 0.5314 - dense_27_loss: 0.6344 - dense_28_loss: 0.6304\n",
      "F1 = 0.5421, ER = 0.5905, F1 = 0.5533, ER = 0.9579, F1 = 0.3448, ER = 1.6690 -  Best val F1s: 0.4800 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 9/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.7607 - dense_26_loss: 0.5242 - dense_27_loss: 0.6244 - dense_28_loss: 0.6120\n",
      "F1 = 0.5390, ER = 0.5935, F1 = 0.5848, ER = 1.0015, F1 = 0.4156, ER = 0.9676 -  Best val F1s: 0.5131 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 10/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.7275 - dense_26_loss: 0.5174 - dense_27_loss: 0.6154 - dense_28_loss: 0.5947\n",
      "F1 = 0.5567, ER = 0.5718, F1 = 0.5968, ER = 1.0374, F1 = 0.4571, ER = 0.7412 -  Best val F1s: 0.5368 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 11/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.7000 - dense_26_loss: 0.5144 - dense_27_loss: 0.6071 - dense_28_loss: 0.5786\n",
      "F1 = 0.5646, ER = 0.5536, F1 = 0.6071, ER = 1.0695, F1 = 0.4969, ER = 0.5571 -  Best val F1s: 0.5562 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 12/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.6677 - dense_26_loss: 0.5060 - dense_27_loss: 0.5985 - dense_28_loss: 0.5632\n",
      "F1 = 0.5906, ER = 0.5137, F1 = 0.6066, ER = 1.1085, F1 = 0.5892, ER = 0.4868 -  Best val F1s: 0.5955 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 13/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.6418 - dense_26_loss: 0.5021 - dense_27_loss: 0.5911 - dense_28_loss: 0.5486\n",
      "F1 = 0.5652, ER = 0.5579, F1 = 0.6321, ER = 1.0031, F1 = 0.5892, ER = 0.4868 -  Best val F1s: 0.5955 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 14/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.6149 - dense_26_loss: 0.4965 - dense_27_loss: 0.5834 - dense_28_loss: 0.5350\n",
      "F1 = 0.5628, ER = 0.5653, F1 = 0.6501, ER = 0.9328, F1 = 0.5892, ER = 0.4868 -  Best val F1s: 0.6007 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 15/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.5949 - dense_26_loss: 0.4960 - dense_27_loss: 0.5767 - dense_28_loss: 0.5222\n",
      "F1 = 0.5909, ER = 0.5141, F1 = 0.6442, ER = 0.9626, F1 = 0.5892, ER = 0.4868 -  Best val F1s: 0.6081 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 16/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.5748 - dense_26_loss: 0.4952 - dense_27_loss: 0.5694 - dense_28_loss: 0.5103\n",
      "F1 = 0.5967, ER = 0.5063, F1 = 0.6609, ER = 0.8846, F1 = 0.5892, ER = 0.4868 -  Best val F1s: 0.6156 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 17/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.5504 - dense_26_loss: 0.4890 - dense_27_loss: 0.5626 - dense_28_loss: 0.4988\n",
      "F1 = 0.5920, ER = 0.5141, F1 = 0.7199, ER = 0.6438, F1 = 0.5892, ER = 0.4868 -  Best val F1s: 0.6337 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 18/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.5322 - dense_26_loss: 0.4873 - dense_27_loss: 0.5567 - dense_28_loss: 0.4882\n",
      "F1 = 0.6083, ER = 0.4907, F1 = 0.7264, ER = 0.6187, F1 = 0.5892, ER = 0.4868 -  Best val F1s: 0.6413 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 19/101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.5161 - dense_26_loss: 0.4871 - dense_27_loss: 0.5509 - dense_28_loss: 0.4781\n",
      "F1 = 0.6022, ER = 0.4998, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6413 (17)\n",
      "\n",
      "Epoch 20/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.4979 - dense_26_loss: 0.4845 - dense_27_loss: 0.5446 - dense_28_loss: 0.4688\n",
      "F1 = 0.5940, ER = 0.5128, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6413 (17)\n",
      "\n",
      "Epoch 21/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.4845 - dense_26_loss: 0.4849 - dense_27_loss: 0.5396 - dense_28_loss: 0.4599\n",
      "F1 = 0.5932, ER = 0.5154, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6413 (17)\n",
      "\n",
      "Epoch 22/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.4668 - dense_26_loss: 0.4806 - dense_27_loss: 0.5344 - dense_28_loss: 0.4517\n",
      "F1 = 0.6035, ER = 0.4985, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6413 (17)\n",
      "\n",
      "Epoch 23/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.4551 - dense_26_loss: 0.4818 - dense_27_loss: 0.5293 - dense_28_loss: 0.4440\n",
      "F1 = 0.6105, ER = 0.4876, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868 -  Best val F1s: 0.6422 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 24/101\n",
      "13992/13992 [==============================] - 2s 161us/step - loss: 1.4376 - dense_26_loss: 0.4770 - dense_27_loss: 0.5239 - dense_28_loss: 0.4367\n",
      "F1 = 0.5882, ER = 0.5241, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6422 (22)\n",
      "\n",
      "Epoch 25/101\n",
      "13992/13992 [==============================] - 2s 157us/step - loss: 1.4263 - dense_26_loss: 0.4771 - dense_27_loss: 0.5193 - dense_28_loss: 0.4299\n",
      "F1 = 0.6014, ER = 0.5007, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6422 (22)\n",
      "\n",
      "Epoch 26/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.4083 - dense_26_loss: 0.4698 - dense_27_loss: 0.5150 - dense_28_loss: 0.4235\n",
      "F1 = 0.5761, ER = 0.5445, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6422 (22)\n",
      "\n",
      "Epoch 27/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.4018 - dense_26_loss: 0.4738 - dense_27_loss: 0.5106 - dense_28_loss: 0.4174\n",
      "F1 = 0.6108, ER = 0.4876, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868 -  Best val F1s: 0.6423 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 28/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.3906 - dense_26_loss: 0.4723 - dense_27_loss: 0.5065 - dense_28_loss: 0.4117\n",
      "F1 = 0.5997, ER = 0.5024, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 29/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.3793 - dense_26_loss: 0.4709 - dense_27_loss: 0.5020 - dense_28_loss: 0.4064\n",
      "F1 = 0.5898, ER = 0.5184, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 30/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.3701 - dense_26_loss: 0.4704 - dense_27_loss: 0.4984 - dense_28_loss: 0.4013\n",
      "F1 = 0.5944, ER = 0.5137, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 31/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.3577 - dense_26_loss: 0.4665 - dense_27_loss: 0.4947 - dense_28_loss: 0.3966\n",
      "F1 = 0.6003, ER = 0.5033, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 32/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.3475 - dense_26_loss: 0.4647 - dense_27_loss: 0.4907 - dense_28_loss: 0.3921\n",
      "F1 = 0.5950, ER = 0.5163, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 33/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.3418 - dense_26_loss: 0.4664 - dense_27_loss: 0.4875 - dense_28_loss: 0.3879\n",
      "F1 = 0.5854, ER = 0.5315, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 34/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.3311 - dense_26_loss: 0.4632 - dense_27_loss: 0.4840 - dense_28_loss: 0.3839\n",
      "F1 = 0.5837, ER = 0.5362, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 35/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.3235 - dense_26_loss: 0.4626 - dense_27_loss: 0.4807 - dense_28_loss: 0.3802\n",
      "F1 = 0.5880, ER = 0.5258, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 36/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.3158 - dense_26_loss: 0.4619 - dense_27_loss: 0.4773 - dense_28_loss: 0.3766\n",
      "F1 = 0.5987, ER = 0.5106, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 37/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.3094 - dense_26_loss: 0.4616 - dense_27_loss: 0.4745 - dense_28_loss: 0.3733\n",
      "F1 = 0.5866, ER = 0.5306, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 38/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.3008 - dense_26_loss: 0.4594 - dense_27_loss: 0.4713 - dense_28_loss: 0.3701\n",
      "F1 = 0.5884, ER = 0.5271, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 39/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.2963 - dense_26_loss: 0.4605 - dense_27_loss: 0.4688 - dense_28_loss: 0.3671\n",
      "F1 = 0.5852, ER = 0.5328, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 40/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.2866 - dense_26_loss: 0.4566 - dense_27_loss: 0.4657 - dense_28_loss: 0.3642\n",
      "F1 = 0.6101, ER = 0.4885, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 41/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.2822 - dense_26_loss: 0.4579 - dense_27_loss: 0.4628 - dense_28_loss: 0.3615\n",
      "F1 = 0.5934, ER = 0.5184, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 42/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.2780 - dense_26_loss: 0.4585 - dense_27_loss: 0.4606 - dense_28_loss: 0.3589\n",
      "F1 = 0.5886, ER = 0.5249, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 43/101\n",
      "13992/13992 [==============================] - 2s 161us/step - loss: 1.2683 - dense_26_loss: 0.4540 - dense_27_loss: 0.4578 - dense_28_loss: 0.3565\n",
      "F1 = 0.5813, ER = 0.5401, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 44/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.2660 - dense_26_loss: 0.4562 - dense_27_loss: 0.4557 - dense_28_loss: 0.3542\n",
      "F1 = 0.5850, ER = 0.5336, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 45/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.2595 - dense_26_loss: 0.4546 - dense_27_loss: 0.4529 - dense_28_loss: 0.3520\n",
      "F1 = 0.5843, ER = 0.5323, F1 = 0.7269, ER = 0.6168, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 46/101\n",
      "13992/13992 [==============================] - 2s 161us/step - loss: 1.2535 - dense_26_loss: 0.4527 - dense_27_loss: 0.4509 - dense_28_loss: 0.3499\n",
      "F1 = 0.5881, ER = 0.5258, F1 = 0.7271, ER = 0.6164, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 47/101\n",
      "13992/13992 [==============================] - 2s 157us/step - loss: 1.2521 - dense_26_loss: 0.4557 - dense_27_loss: 0.4485 - dense_28_loss: 0.3478\n",
      "F1 = 0.5912, ER = 0.5228, F1 = 0.7270, ER = 0.6160, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 48/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.2491 - dense_26_loss: 0.4566 - dense_27_loss: 0.4466 - dense_28_loss: 0.3459\n",
      "F1 = 0.5778, ER = 0.5488, F1 = 0.7269, ER = 0.5886, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 49/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.2403 - dense_26_loss: 0.4518 - dense_27_loss: 0.4445 - dense_28_loss: 0.3441\n",
      "F1 = 0.5765, ER = 0.5505, F1 = 0.7264, ER = 0.5882, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 50/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.2352 - dense_26_loss: 0.4505 - dense_27_loss: 0.4423 - dense_28_loss: 0.3424\n",
      "F1 = 0.5779, ER = 0.5471, F1 = 0.7251, ER = 0.5797, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 51/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.2293 - dense_26_loss: 0.4482 - dense_27_loss: 0.4403 - dense_28_loss: 0.3408\n",
      "F1 = 0.5839, ER = 0.5349, F1 = 0.7212, ER = 0.5612, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 52/101\n",
      "13992/13992 [==============================] - 2s 157us/step - loss: 1.2265 - dense_26_loss: 0.4489 - dense_27_loss: 0.4384 - dense_28_loss: 0.3392\n",
      "F1 = 0.5781, ER = 0.5479, F1 = 0.7192, ER = 0.5747, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 53/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.2242 - dense_26_loss: 0.4494 - dense_27_loss: 0.4371 - dense_28_loss: 0.3377\n",
      "F1 = 0.5890, ER = 0.5284, F1 = 0.7185, ER = 0.5488, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 54/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.2200 - dense_26_loss: 0.4486 - dense_27_loss: 0.4351 - dense_28_loss: 0.3363\n",
      "F1 = 0.5797, ER = 0.5423, F1 = 0.7179, ER = 0.5619, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 55/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.2192 - dense_26_loss: 0.4509 - dense_27_loss: 0.4334 - dense_28_loss: 0.3349\n",
      "F1 = 0.5764, ER = 0.5458, F1 = 0.7169, ER = 0.5612, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 56/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.2105 - dense_26_loss: 0.4452 - dense_27_loss: 0.4316 - dense_28_loss: 0.3336\n",
      "F1 = 0.5758, ER = 0.5501, F1 = 0.7150, ER = 0.5573, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 57/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.2122 - dense_26_loss: 0.4495 - dense_27_loss: 0.4303 - dense_28_loss: 0.3323\n",
      "F1 = 0.5931, ER = 0.5206, F1 = 0.7174, ER = 0.5125, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 58/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.2088 - dense_26_loss: 0.4490 - dense_27_loss: 0.4287 - dense_28_loss: 0.3311\n",
      "F1 = 0.5866, ER = 0.5319, F1 = 0.7129, ER = 0.5149, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 59/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.2030 - dense_26_loss: 0.4461 - dense_27_loss: 0.4270 - dense_28_loss: 0.3300\n",
      "F1 = 0.5854, ER = 0.5336, F1 = 0.7103, ER = 0.4114, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 60/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1989 - dense_26_loss: 0.4444 - dense_27_loss: 0.4255 - dense_28_loss: 0.3289\n",
      "F1 = 0.5857, ER = 0.5345, F1 = 0.7075, ER = 0.4025, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 61/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1983 - dense_26_loss: 0.4462 - dense_27_loss: 0.4244 - dense_28_loss: 0.3278\n",
      "F1 = 0.5812, ER = 0.5388, F1 = 0.7076, ER = 0.3979, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 62/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1968 - dense_26_loss: 0.4464 - dense_27_loss: 0.4236 - dense_28_loss: 0.3268\n",
      "F1 = 0.5795, ER = 0.5432, F1 = 0.7065, ER = 0.3983, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 63/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1943 - dense_26_loss: 0.4464 - dense_27_loss: 0.4220 - dense_28_loss: 0.3259\n",
      "F1 = 0.5950, ER = 0.5189, F1 = 0.7059, ER = 0.4010, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 64/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1926 - dense_26_loss: 0.4469 - dense_27_loss: 0.4208 - dense_28_loss: 0.3249\n",
      "F1 = 0.5745, ER = 0.5527, F1 = 0.7072, ER = 0.3964, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 65/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1897 - dense_26_loss: 0.4463 - dense_27_loss: 0.4193 - dense_28_loss: 0.3241\n",
      "F1 = 0.5789, ER = 0.5440, F1 = 0.7089, ER = 0.4072, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 66/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1858 - dense_26_loss: 0.4440 - dense_27_loss: 0.4186 - dense_28_loss: 0.3232\n",
      "F1 = 0.5794, ER = 0.5440, F1 = 0.7064, ER = 0.3825, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 67/101\n",
      "13992/13992 [==============================] - 2s 157us/step - loss: 1.1874 - dense_26_loss: 0.4477 - dense_27_loss: 0.4173 - dense_28_loss: 0.3224\n",
      "F1 = 0.5792, ER = 0.5453, F1 = 0.7068, ER = 0.3755, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 68/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.1821 - dense_26_loss: 0.4441 - dense_27_loss: 0.4163 - dense_28_loss: 0.3217\n",
      "F1 = 0.5674, ER = 0.5501, F1 = 0.7055, ER = 0.4114, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 69/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1814 - dense_26_loss: 0.4450 - dense_27_loss: 0.4155 - dense_28_loss: 0.3209\n",
      "F1 = 0.5846, ER = 0.5354, F1 = 0.6983, ER = 0.3640, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 70/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1788 - dense_26_loss: 0.4442 - dense_27_loss: 0.4143 - dense_28_loss: 0.3202\n",
      "F1 = 0.5752, ER = 0.5436, F1 = 0.7050, ER = 0.3917, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 71/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1758 - dense_26_loss: 0.4432 - dense_27_loss: 0.4131 - dense_28_loss: 0.3195\n",
      "F1 = 0.5752, ER = 0.5501, F1 = 0.7025, ER = 0.3659, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 72/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1761 - dense_26_loss: 0.4446 - dense_27_loss: 0.4127 - dense_28_loss: 0.3189\n",
      "F1 = 0.5803, ER = 0.5440, F1 = 0.6901, ER = 0.3369, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 73/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1731 - dense_26_loss: 0.4434 - dense_27_loss: 0.4114 - dense_28_loss: 0.3182\n",
      "F1 = 0.5732, ER = 0.5514, F1 = 0.6981, ER = 0.3655, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 74/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1715 - dense_26_loss: 0.4428 - dense_27_loss: 0.4110 - dense_28_loss: 0.3177\n",
      "F1 = 0.5933, ER = 0.5202, F1 = 0.6911, ER = 0.3393, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 75/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.1700 - dense_26_loss: 0.4427 - dense_27_loss: 0.4102 - dense_28_loss: 0.3171\n",
      "F1 = 0.5928, ER = 0.5193, F1 = 0.7015, ER = 0.3539, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 76/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.1684 - dense_26_loss: 0.4428 - dense_27_loss: 0.4090 - dense_28_loss: 0.3166\n",
      "F1 = 0.5764, ER = 0.5475, F1 = 0.6963, ER = 0.3404, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 77/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1646 - dense_26_loss: 0.4405 - dense_27_loss: 0.4080 - dense_28_loss: 0.3161\n",
      "F1 = 0.5747, ER = 0.5501, F1 = 0.7034, ER = 0.3524, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 78/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1660 - dense_26_loss: 0.4430 - dense_27_loss: 0.4074 - dense_28_loss: 0.3156\n",
      "F1 = 0.5709, ER = 0.5570, F1 = 0.7004, ER = 0.3535, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 79/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.1654 - dense_26_loss: 0.4437 - dense_27_loss: 0.4066 - dense_28_loss: 0.3152\n",
      "F1 = 0.5409, ER = 0.5449, F1 = 0.6876, ER = 0.3968, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 80/101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1622 - dense_26_loss: 0.4412 - dense_27_loss: 0.4062 - dense_28_loss: 0.3147\n",
      "F1 = 0.5673, ER = 0.5566, F1 = 0.6971, ER = 0.3589, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 81/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.1599 - dense_26_loss: 0.4403 - dense_27_loss: 0.4053 - dense_28_loss: 0.3143\n",
      "F1 = 0.5672, ER = 0.5475, F1 = 0.6837, ER = 0.3686, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 82/101\n",
      "13992/13992 [==============================] - 2s 161us/step - loss: 1.1621 - dense_26_loss: 0.4431 - dense_27_loss: 0.4052 - dense_28_loss: 0.3138\n",
      "F1 = 0.5567, ER = 0.5614, F1 = 0.6851, ER = 0.3643, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 83/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.1600 - dense_26_loss: 0.4427 - dense_27_loss: 0.4039 - dense_28_loss: 0.3135\n",
      "F1 = 0.5775, ER = 0.5475, F1 = 0.6947, ER = 0.3350, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 84/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.1584 - dense_26_loss: 0.4418 - dense_27_loss: 0.4035 - dense_28_loss: 0.3131\n",
      "F1 = 0.5586, ER = 0.5523, F1 = 0.6843, ER = 0.3624, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 85/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.1573 - dense_26_loss: 0.4413 - dense_27_loss: 0.4032 - dense_28_loss: 0.3128\n",
      "F1 = 0.5710, ER = 0.5557, F1 = 0.6811, ER = 0.3192, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 86/101\n",
      "13992/13992 [==============================] - 2s 157us/step - loss: 1.1554 - dense_26_loss: 0.4406 - dense_27_loss: 0.4023 - dense_28_loss: 0.3125\n",
      "F1 = 0.5560, ER = 0.5531, F1 = 0.6714, ER = 0.3296, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 87/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1554 - dense_26_loss: 0.4412 - dense_27_loss: 0.4020 - dense_28_loss: 0.3121\n",
      "F1 = 0.5493, ER = 0.5440, F1 = 0.6732, ER = 0.3555, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 88/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1530 - dense_26_loss: 0.4398 - dense_27_loss: 0.4014 - dense_28_loss: 0.3118\n",
      "F1 = 0.5429, ER = 0.5393, F1 = 0.6757, ER = 0.3775, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 89/101\n",
      "13992/13992 [==============================] - 2s 161us/step - loss: 1.1547 - dense_26_loss: 0.4423 - dense_27_loss: 0.4009 - dense_28_loss: 0.3115\n",
      "F1 = 0.5654, ER = 0.5557, F1 = 0.6784, ER = 0.3284, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 90/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1530 - dense_26_loss: 0.4414 - dense_27_loss: 0.4003 - dense_28_loss: 0.3113\n",
      "F1 = 0.5741, ER = 0.5479, F1 = 0.6779, ER = 0.3250, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 91/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1505 - dense_26_loss: 0.4395 - dense_27_loss: 0.4000 - dense_28_loss: 0.3110\n",
      "F1 = 0.5559, ER = 0.5601, F1 = 0.6761, ER = 0.3261, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 92/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1492 - dense_26_loss: 0.4388 - dense_27_loss: 0.3996 - dense_28_loss: 0.3108\n",
      "F1 = 0.5748, ER = 0.5518, F1 = 0.6690, ER = 0.3497, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 93/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.1518 - dense_26_loss: 0.4417 - dense_27_loss: 0.3995 - dense_28_loss: 0.3105\n",
      "F1 = 0.5830, ER = 0.5384, F1 = 0.6725, ER = 0.3423, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 94/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1495 - dense_26_loss: 0.4403 - dense_27_loss: 0.3990 - dense_28_loss: 0.3103\n",
      "F1 = 0.5567, ER = 0.5614, F1 = 0.6793, ER = 0.3238, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 95/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1482 - dense_26_loss: 0.4400 - dense_27_loss: 0.3982 - dense_28_loss: 0.3100\n",
      "F1 = 0.5736, ER = 0.5544, F1 = 0.6705, ER = 0.3516, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 96/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1473 - dense_26_loss: 0.4398 - dense_27_loss: 0.3976 - dense_28_loss: 0.3099\n",
      "F1 = 0.5590, ER = 0.5705, F1 = 0.6783, ER = 0.3331, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 97/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1486 - dense_26_loss: 0.4414 - dense_27_loss: 0.3975 - dense_28_loss: 0.3097\n",
      "F1 = 0.5339, ER = 0.5492, F1 = 0.6656, ER = 0.3400, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 98/101\n",
      "13992/13992 [==============================] - 2s 157us/step - loss: 1.1485 - dense_26_loss: 0.4415 - dense_27_loss: 0.3974 - dense_28_loss: 0.3095\n",
      "F1 = 0.5731, ER = 0.5544, F1 = 0.6725, ER = 0.3439, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 99/101\n",
      "13992/13992 [==============================] - 2s 159us/step - loss: 1.1447 - dense_26_loss: 0.4388 - dense_27_loss: 0.3966 - dense_28_loss: 0.3093\n",
      "F1 = 0.5693, ER = 0.5553, F1 = 0.6757, ER = 0.3362, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 100/101\n",
      "13992/13992 [==============================] - 2s 160us/step - loss: 1.1459 - dense_26_loss: 0.4406 - dense_27_loss: 0.3961 - dense_28_loss: 0.3091\n",
      "F1 = 0.5768, ER = 0.5488, F1 = 0.6859, ER = 0.3265, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n",
      "Epoch 101/101\n",
      "13992/13992 [==============================] - 2s 158us/step - loss: 1.1442 - dense_26_loss: 0.4391 - dense_27_loss: 0.3961 - dense_28_loss: 0.3090\n",
      "F1 = 0.5778, ER = 0.5475, F1 = 0.6785, ER = 0.3443, F1 = 0.5892, ER = 0.4868  - Best val F1s: 0.6423 (26)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'sequence_time': sequence_time, 'sequence_hop_time':sequence_hop_time,\n",
    "          'label_list':label_list, 'audio_hop':audio_hop, 'audio_win':audio_win,\n",
    "          'n_fft':n_fft,'sr':sr,'mel_bands':mel_bands,'normalize':normalize_data, 'frames':frames,\n",
    "          'get_annotations':get_annotations, 'dataset': 'MAVD'}\n",
    "\n",
    "sequence_frames = int(np.ceil(sequence_time*sr/audio_hop))\n",
    "\n",
    "# Datasets\n",
    "partition = {}# IDs\n",
    "labels = {}# Labels\n",
    "\n",
    "train_files = sorted(glob.glob(os.path.join(audio_folder,'train', '*.flac')))\n",
    "val_files = sorted(glob.glob(os.path.join(audio_folder,'validate', '*.flac')))\n",
    "\n",
    "if load_subset is not None:\n",
    "    train_files = train_files[:load_subset]\n",
    "    val_files = val_files[:load_subset]\n",
    "\n",
    "train_labels = {}\n",
    "train_mel = {}\n",
    "val_labels = {}\n",
    "val_mel = {}\n",
    "mel_basis = librosa.filters.mel(sr,n_fft,mel_bands,htk=True)\n",
    "print('Founding scaler')\n",
    "for n,id in enumerate(train_files):\n",
    "    labels[id] = os.path.join(label_folder, 'train',os.path.basename(id).replace('.flac','.txt'))\n",
    "for id in val_files:\n",
    "    labels[id] = os.path.join(label_folder, 'validate',os.path.basename(id).replace('.flac','.txt'))\n",
    "\n",
    "params['train'] = True\n",
    "# Generators\n",
    "print('Making generators')\n",
    "training_generator = DataGenerator(train_files, labels, **params)\n",
    "scaler = training_generator.get_scaler()\n",
    "\n",
    "params['scaler'] = scaler\n",
    "params['train'] = False\n",
    "params['sequence_hop_time'] = sequence_time\n",
    "\n",
    "validation_generator = DataGenerator(val_files, labels, **params)\n",
    "\n",
    "print('Getting data')\n",
    "\n",
    "\n",
    "_,train_example,train_mel_example,train_y_example = training_generator.return_random()\n",
    "_,val_example,val_mel_example,val_y_example = validation_generator.return_random()\n",
    "\n",
    "_,_,x_val,y_val = validation_generator.return_all()\n",
    "_,_,x_train,y_train = training_generator.return_all()\n",
    "\n",
    "if not frames:    \n",
    "    x_train = np.transpose(x_train,(0,2,1))    \n",
    "    x_val = np.transpose(x_val,(0,2,1))  \n",
    "    val_example = np.transpose(val_example,(0,2,1))     \n",
    "\n",
    "y_val_level1 = y_val[0]\n",
    "y_val_level2 = y_val[1]\n",
    "y_val_level3 = y_val[2]\n",
    "\n",
    "y_train_level1 = y_train[0]\n",
    "y_train_level2 = y_train[1]\n",
    "y_train_level3 = y_train[2]\n",
    "\n",
    "\n",
    "print('train',x_train.shape)    \n",
    "print('val',x_val.shape)     \n",
    "\n",
    "sequence_frames = x_val.shape[1]\n",
    "scaler2 = training_generator.get_standard_scaler()\n",
    "\n",
    "mean= scaler2.mean_\n",
    "scale = scaler2.scale_\n",
    "\n",
    "# Build model\n",
    "\n",
    "print('\\nBuilding model...')\n",
    "\n",
    "sequence_samples = int(sequence_time*sr)\n",
    "\n",
    "model_folder = \"../exps/S-CNN_baseline/weights_best.hdf5\"\n",
    "\n",
    "model = cnn_fine_tuned(n_freq_cnn=mel_bands, n_frames_cnn=sequence_frames,large_cnn=large_cnn,\n",
    "                      n_classes1=len(class_list1),n_classes2=len(class_list2),n_classes3=len(class_list3),\n",
    "                      model_baseline=model_folder)\n",
    "\n",
    "# Change batch normalization in first layer for the new dataset\n",
    "model.layers[1].set_weights([np.ones_like(mean),np.zeros_like(mean),mean,scale])\n",
    "\n",
    "# Only train new layers\n",
    "for j in range(len(model.layers)-4):\n",
    "    model.layers[j].trainable=False\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = Adam(lr=learning_rate*0.2)\n",
    "\n",
    "# Fit model\n",
    "print('\\nFitting model...')\n",
    "\n",
    "if resume:\n",
    "    f1s_best = resume_f1_best\n",
    "\n",
    "metrics_callback = MetricsCallback_levels(x_val, [y_val_level1,y_val_level2,y_val_level3], 0, 0, \n",
    "                                          os.path.join(expfolder, 'weights_best.hdf5'))\n",
    "csv_logger = CSVLogger(os.path.join(expfolder,'training.log'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=opt)#, loss_weights=loss_w)\n",
    "\n",
    "history = model.fit(x=x_train, y=[y_train_level1,y_train_level2,y_train_level3], batch_size=2*batch_size,\n",
    "                            epochs=epochs, verbose=fit_verbose,\n",
    "                            validation_split=0.0,\n",
    "                            shuffle=True,\n",
    "                            callbacks=[metrics_callback,csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
