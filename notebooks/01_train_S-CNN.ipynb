{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "from mavd.model import build_custom_cnn\n",
    "from mavd.callbacks import MetricsCallback\n",
    "from mavd.data_generator import DataGenerator\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files parameters\n",
    "Nfiles = None\n",
    "resume = False\n",
    "load_subset = Nfiles\n",
    "\n",
    "# audio parameters\n",
    "sr = 22050\n",
    "sequence_time = 1.0\n",
    "sequence_hop_time = 1.0\n",
    "audio_hop = 512\n",
    "audio_win = 1024\n",
    "n_fft = 1024\n",
    "normalize_data = 'none' # para comparar loss con MST\n",
    "get_annotations = True\n",
    "mel_bands = 128\n",
    "htk = True\n",
    "normalize_energy = True\n",
    "\n",
    "# training\n",
    "learning_rate = 0.001\n",
    "epochs = 101\n",
    "batch_size = 64\n",
    "sed_early_stopping = 100\n",
    "epoch_limit = None\n",
    "fit_verbose = True\n",
    "fine_tuning = False\n",
    "\n",
    "#model\n",
    "large_cnn = True\n",
    "frames = True\n",
    "\n",
    "label_list = (['air_conditioner', 'car_horn', 'children_playing',\n",
    "               'dog_bark', 'drilling', 'engine_idling', 'gun_shot',\n",
    "               'jackhammer', 'siren', 'street_music'])  \n",
    "\n",
    " # Create output folders\n",
    "expfolder = '../exps/S-CNN_baseline/'\n",
    "\n",
    "audio_folder = '/data_ssd/users/pzinemanas/maestria/URBAN-SED/audio22050'\n",
    "label_folder='/data_ssd/users/pzinemanas/maestria/URBAN-SED/annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Founding scaler\n",
      "Making generators\n",
      "Getting data\n",
      "(440, 128)\n",
      "(2640000, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 13:25:36.044090 140142706325248 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 44, 128)\n",
      "(20000, 44, 128)\n",
      "(20000, 44, 128) (10,) (10,)\n",
      "\n",
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 13:25:36.527404 140142706325248 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0829 13:25:36.802807 140142706325248 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0829 13:25:36.851987 140142706325248 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0829 13:25:36.895498 140142706325248 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0829 13:25:36.906251 140142706325248 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0829 13:25:47.000200 140142706325248 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0829 13:25:47.148385 140142706325248 deprecation.py:506] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0829 13:25:47.379549 140142706325248 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 44, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 128)           512       \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 44, 128, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 40, 124, 128)      3328      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 62, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 58, 128)       409728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 29, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 29, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 25, 128)        409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 25, 128)        512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,481,162\n",
      "Trainable params: 2,480,138\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "\n",
      "Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 13:25:48.014041 140142706325248 deprecation.py:323] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/101\n",
      "60000/60000 [==============================] - 31s 521us/step - loss: 0.3811\n",
      "F1 = 0.0027, ER = 0.9987 -  Best val F1s: 0.0027 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 2/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.3434\n",
      "F1 = 0.0000, ER = 1.0000 - Best val F1s: 0.0027 (0)\n",
      "\n",
      "Epoch 3/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.3389\n",
      "F1 = 0.0098, ER = 0.9951 -  Best val F1s: 0.0098 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 4/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.3364\n",
      "F1 = 0.0371, ER = 0.9809 -  Best val F1s: 0.0371 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 5/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3353\n",
      "F1 = 0.0212, ER = 0.9892 - Best val F1s: 0.0371 (3)\n",
      "\n",
      "Epoch 6/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3344\n",
      "F1 = 0.0195, ER = 0.9902 - Best val F1s: 0.0371 (3)\n",
      "\n",
      "Epoch 7/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3319\n",
      "F1 = 0.0183, ER = 0.9907 - Best val F1s: 0.0371 (3)\n",
      "\n",
      "Epoch 8/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3301\n",
      "F1 = 0.0178, ER = 0.9910 - Best val F1s: 0.0371 (3)\n",
      "\n",
      "Epoch 9/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3282\n",
      "F1 = 0.0402, ER = 0.9794 -  Best val F1s: 0.0402 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 10/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3256\n",
      "F1 = 0.0709, ER = 0.9626 -  Best val F1s: 0.0709 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 11/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.3217\n",
      "F1 = 0.0424, ER = 0.9783 - Best val F1s: 0.0709 (9)\n",
      "\n",
      "Epoch 12/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.3161\n",
      "F1 = 0.0423, ER = 0.9783 - Best val F1s: 0.0709 (9)\n",
      "\n",
      "Epoch 13/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3120\n",
      "F1 = 0.0780, ER = 0.9591 -  Best val F1s: 0.0780 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 14/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.3081\n",
      "F1 = 0.0939, ER = 0.9501 -  Best val F1s: 0.0939 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 15/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.3035\n",
      "F1 = 0.1351, ER = 0.9253 -  Best val F1s: 0.1351 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 16/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2979\n",
      "F1 = 0.1317, ER = 0.9286 - Best val F1s: 0.1351 (14)\n",
      "\n",
      "Epoch 17/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2926\n",
      "F1 = 0.1727, ER = 0.9035 -  Best val F1s: 0.1727 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 18/101\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.2861\n",
      "F1 = 0.2372, ER = 0.8604 -  Best val F1s: 0.2372 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 19/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2801\n",
      "F1 = 0.2713, ER = 0.8362 -  Best val F1s: 0.2713 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 20/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2748\n",
      "F1 = 0.2819, ER = 0.8261 -  Best val F1s: 0.2819 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 21/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2685\n",
      "F1 = 0.3342, ER = 0.7907 -  Best val F1s: 0.3342 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 22/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2638\n",
      "F1 = 0.3273, ER = 0.7940 - Best val F1s: 0.3342 (20)\n",
      "\n",
      "Epoch 23/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2596\n",
      "F1 = 0.3505, ER = 0.7741 -  Best val F1s: 0.3505 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 24/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2550\n",
      "F1 = 0.3899, ER = 0.7423 -  Best val F1s: 0.3899 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 25/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2507\n",
      "F1 = 0.4006, ER = 0.7329 -  Best val F1s: 0.4006 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 26/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2467\n",
      "F1 = 0.4145, ER = 0.7180 -  Best val F1s: 0.4145 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 27/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2430\n",
      "F1 = 0.4149, ER = 0.7184 -  Best val F1s: 0.4149 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 28/101\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.2397\n",
      "F1 = 0.4292, ER = 0.7050 -  Best val F1s: 0.4292 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 29/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2370\n",
      "F1 = 0.4538, ER = 0.6784 -  Best val F1s: 0.4538 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 30/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2334\n",
      "F1 = 0.4613, ER = 0.6694 -  Best val F1s: 0.4613 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 31/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2313\n",
      "F1 = 0.4616, ER = 0.6682 -  Best val F1s: 0.4616 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 32/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2278\n",
      "F1 = 0.4528, ER = 0.6761 - Best val F1s: 0.4616 (30)\n",
      "\n",
      "Epoch 33/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2260\n",
      "F1 = 0.4700, ER = 0.6570 -  Best val F1s: 0.4700 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 34/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2235\n",
      "F1 = 0.4710, ER = 0.6584 -  Best val F1s: 0.4710 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 35/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2208\n",
      "F1 = 0.4654, ER = 0.6635 - Best val F1s: 0.4710 (33)\n",
      "\n",
      "Epoch 36/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2185\n",
      "F1 = 0.4836, ER = 0.6425 -  Best val F1s: 0.4836 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 37/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2168\n",
      "F1 = 0.4815, ER = 0.6442 - Best val F1s: 0.4836 (35)\n",
      "\n",
      "Epoch 38/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2145\n",
      "F1 = 0.4849, ER = 0.6391 -  Best val F1s: 0.4849 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 39/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2124\n",
      "F1 = 0.4876, ER = 0.6423 -  Best val F1s: 0.4876 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 40/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2107\n",
      "F1 = 0.5001, ER = 0.6253 -  Best val F1s: 0.5001 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 41/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2087\n",
      "F1 = 0.4903, ER = 0.6343 - Best val F1s: 0.5001 (39)\n",
      "\n",
      "Epoch 42/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2066\n",
      "F1 = 0.5078, ER = 0.6129 -  Best val F1s: 0.5078 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 43/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2041\n",
      "F1 = 0.4965, ER = 0.6219 - Best val F1s: 0.5078 (41)\n",
      "\n",
      "Epoch 44/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2035\n",
      "F1 = 0.4826, ER = 0.6363 - Best val F1s: 0.5078 (41)\n",
      "\n",
      "Epoch 45/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2012\n",
      "F1 = 0.5116, ER = 0.6041 -  Best val F1s: 0.5116 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 46/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2001\n",
      "F1 = 0.5016, ER = 0.6166 - Best val F1s: 0.5116 (44)\n",
      "\n",
      "Epoch 47/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1983\n",
      "F1 = 0.5082, ER = 0.6107 - Best val F1s: 0.5116 (44)\n",
      "\n",
      "Epoch 48/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1962\n",
      "F1 = 0.5156, ER = 0.6035 -  Best val F1s: 0.5156 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 49/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1947\n",
      "F1 = 0.5067, ER = 0.6110 - Best val F1s: 0.5156 (47)\n",
      "\n",
      "Epoch 50/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1937\n",
      "F1 = 0.5085, ER = 0.6044 - Best val F1s: 0.5156 (47)\n",
      "\n",
      "Epoch 51/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1924\n",
      "F1 = 0.5165, ER = 0.5943 -  Best val F1s: 0.5165 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 52/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1906\n",
      "F1 = 0.5124, ER = 0.6016 - Best val F1s: 0.5165 (50)\n",
      "\n",
      "Epoch 53/101\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.1889\n",
      "F1 = 0.5056, ER = 0.6049 - Best val F1s: 0.5165 (50)\n",
      "\n",
      "Epoch 54/101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1884\n",
      "F1 = 0.5183, ER = 0.5913 -  Best val F1s: 0.5183 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 55/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1865\n",
      "F1 = 0.5167, ER = 0.5898 - Best val F1s: 0.5183 (53)\n",
      "\n",
      "Epoch 56/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1852\n",
      "F1 = 0.5195, ER = 0.5870 -  Best val F1s: 0.5195 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 57/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1832\n",
      "F1 = 0.5128, ER = 0.5964 - Best val F1s: 0.5195 (55)\n",
      "\n",
      "Epoch 58/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1824\n",
      "F1 = 0.5224, ER = 0.5820 -  Best val F1s: 0.5224 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 59/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1818\n",
      "F1 = 0.5201, ER = 0.5880 - Best val F1s: 0.5224 (57)\n",
      "\n",
      "Epoch 60/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1801\n",
      "F1 = 0.5156, ER = 0.5971 - Best val F1s: 0.5224 (57)\n",
      "\n",
      "Epoch 61/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1789\n",
      "F1 = 0.5305, ER = 0.5684 -  Best val F1s: 0.5305 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 62/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1775\n",
      "F1 = 0.5195, ER = 0.5889 - Best val F1s: 0.5305 (60)\n",
      "\n",
      "Epoch 63/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1768\n",
      "F1 = 0.5281, ER = 0.5699 - Best val F1s: 0.5305 (60)\n",
      "\n",
      "Epoch 64/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1757\n",
      "F1 = 0.5306, ER = 0.5722 -  Best val F1s: 0.5306 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 65/101\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.1739\n",
      "F1 = 0.5220, ER = 0.5843 - Best val F1s: 0.5306 (63)\n",
      "\n",
      "Epoch 66/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1734\n",
      "F1 = 0.5235, ER = 0.5743 - Best val F1s: 0.5306 (63)\n",
      "\n",
      "Epoch 67/101\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.1728\n",
      "F1 = 0.5271, ER = 0.5741 - Best val F1s: 0.5306 (63)\n",
      "\n",
      "Epoch 68/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1717\n",
      "F1 = 0.5331, ER = 0.5643 -  Best val F1s: 0.5331 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 69/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1697\n",
      "F1 = 0.5228, ER = 0.5747 - Best val F1s: 0.5331 (67)\n",
      "\n",
      "Epoch 70/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1694\n",
      "F1 = 0.5239, ER = 0.5763 - Best val F1s: 0.5331 (67)\n",
      "\n",
      "Epoch 71/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1678\n",
      "F1 = 0.5232, ER = 0.5731 - Best val F1s: 0.5331 (67)\n",
      "\n",
      "Epoch 72/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1670\n",
      "F1 = 0.5185, ER = 0.5874 - Best val F1s: 0.5331 (67)\n",
      "\n",
      "Epoch 73/101\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.1659\n",
      "F1 = 0.5256, ER = 0.5709 - Best val F1s: 0.5331 (67)\n",
      "\n",
      "Epoch 74/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1660\n",
      "F1 = 0.5292, ER = 0.5690 - Best val F1s: 0.5331 (67)\n",
      "\n",
      "Epoch 75/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1646\n",
      "F1 = 0.5281, ER = 0.5649 - Best val F1s: 0.5331 (67)\n",
      "\n",
      "Epoch 76/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1630\n",
      "F1 = 0.5256, ER = 0.5718 - Best val F1s: 0.5331 (67)\n",
      "\n",
      "Epoch 77/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1627\n",
      "F1 = 0.5400, ER = 0.5578 -  Best val F1s: 0.5400 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 78/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1613\n",
      "F1 = 0.5424, ER = 0.5442 -  Best val F1s: 0.5424 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 79/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1603\n",
      "F1 = 0.5439, ER = 0.5459 -  Best val F1s: 0.5439 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 80/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1602\n",
      "F1 = 0.5219, ER = 0.5780 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 81/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1588\n",
      "F1 = 0.5419, ER = 0.5511 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 82/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1581\n",
      "F1 = 0.5298, ER = 0.5681 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 83/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1570\n",
      "F1 = 0.5322, ER = 0.5635 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 84/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1554\n",
      "F1 = 0.5267, ER = 0.5640 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 85/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1561\n",
      "F1 = 0.5355, ER = 0.5585 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 86/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1547\n",
      "F1 = 0.5139, ER = 0.5853 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 87/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1553\n",
      "F1 = 0.5416, ER = 0.5438 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 88/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1534\n",
      "F1 = 0.5287, ER = 0.5691 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 89/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1525\n",
      "F1 = 0.5235, ER = 0.5707 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 90/101\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.1516\n",
      "F1 = 0.5342, ER = 0.5559 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 91/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1508\n",
      "F1 = 0.5312, ER = 0.5572 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 92/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1496\n",
      "F1 = 0.5382, ER = 0.5470 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 93/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1500\n",
      "F1 = 0.5338, ER = 0.5559 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 94/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1492\n",
      "F1 = 0.5278, ER = 0.5624 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 95/101\n",
      "60000/60000 [==============================] - 24s 406us/step - loss: 0.1482\n",
      "F1 = 0.5354, ER = 0.5599 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 96/101\n",
      "60000/60000 [==============================] - 24s 407us/step - loss: 0.1467\n",
      "F1 = 0.5250, ER = 0.5647 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 97/101\n",
      "60000/60000 [==============================] - 24s 407us/step - loss: 0.1471\n",
      "F1 = 0.5249, ER = 0.5714 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 98/101\n",
      "60000/60000 [==============================] - 24s 406us/step - loss: 0.1458\n",
      "F1 = 0.5248, ER = 0.5732 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 99/101\n",
      "60000/60000 [==============================] - 24s 406us/step - loss: 0.1461\n",
      "F1 = 0.5335, ER = 0.5594 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 100/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1444\n",
      "F1 = 0.5311, ER = 0.5591 - Best val F1s: 0.5439 (78)\n",
      "\n",
      "Epoch 101/101\n",
      "60000/60000 [==============================] - 24s 406us/step - loss: 0.1439\n",
      "F1 = 0.5409, ER = 0.5494 - Best val F1s: 0.5439 (78)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'files_batch':20, 'path':audio_folder, 'sequence_time': sequence_time, \n",
    "          'sequence_hop_time':sequence_hop_time,'label_list':label_list,\n",
    "          'normalize_energy':normalize_energy,'audio_hop':audio_hop, 'audio_win':audio_win,\n",
    "          'n_fft':n_fft,'sr':sr,'mel_bands':mel_bands,'normalize':normalize_data, 'frames':frames,\n",
    "          'get_annotations':get_annotations, 'dataset': 'URBAN-SED'}\n",
    "\n",
    "sequence_frames = int(np.ceil(sequence_time*sr/audio_hop))\n",
    "\n",
    "# Datasets\n",
    "partition = {}# IDs\n",
    "labels = {}# Labels\n",
    "\n",
    "train_files = sorted(glob.glob(os.path.join(audio_folder,'train', '*.wav')))\n",
    "val_files = sorted(glob.glob(os.path.join(audio_folder,'validate', '*.wav')))\n",
    "\n",
    "if load_subset is not None:\n",
    "    train_files = train_files[:load_subset]\n",
    "    val_files = val_files[:load_subset]\n",
    "\n",
    "train_labels = {}\n",
    "train_mel = {}\n",
    "val_labels = {}\n",
    "val_mel = {}\n",
    "mel_basis = librosa.filters.mel(sr,n_fft,mel_bands,htk=True)\n",
    "print('Founding scaler')\n",
    "for n,id in enumerate(train_files):\n",
    "    labels[id] = os.path.join(label_folder, 'train',os.path.basename(id).replace('.wav','.txt'))\n",
    "    #train_mel[id]  = os.path.join(mel_folder, 'train',os.path.basename(id).replace('.wav','.npy.gz'))\n",
    "for id in val_files:\n",
    "    labels[id] = os.path.join(label_folder, 'validate',os.path.basename(id).replace('.wav','.txt'))\n",
    "\n",
    "params['train'] = True\n",
    "# Generators\n",
    "print('Making generators')\n",
    "training_generator = DataGenerator(train_files, labels, **params)\n",
    "scaler = training_generator.get_scaler()\n",
    "#print('scaler',scaler)\n",
    "\n",
    "params['scaler'] = scaler\n",
    "params['train'] = False\n",
    "params['sequence_hop_time'] = sequence_time\n",
    "\n",
    "validation_generator = DataGenerator(val_files, labels, **params)\n",
    "\n",
    "print('Getting data')\n",
    "\n",
    "train_example,_,train_mel_example,train_y_example = training_generator.return_random()\n",
    "_,_,val_example,val_y_example = validation_generator.return_random()\n",
    "\n",
    "_,_,x_val,y_val = validation_generator.return_all()\n",
    "_,_,x_train,y_train = training_generator.return_all()\n",
    "\n",
    "if not frames:    \n",
    "    x_train = np.transpose(x_train,(0,2,1))    \n",
    "    x_val = np.transpose(x_val,(0,2,1))  \n",
    "    val_example = np.transpose(val_example,(0,2,1))     \n",
    "\n",
    "\n",
    "print(x_train.shape)    \n",
    "print(x_val.shape)     \n",
    "\n",
    "print(x_val.shape,y_val[0].shape,y_val[1].shape)\n",
    "sequence_frames = x_val.shape[1]\n",
    "standard_scaler = training_generator.get_standard_scaler()\n",
    "\n",
    "mean= standard_scaler.mean_\n",
    "scale = standard_scaler.scale_\n",
    "\n",
    "# Build model\n",
    "\n",
    "print('\\nBuilding model...')\n",
    "\n",
    "sequence_samples = int(sequence_time*sr)\n",
    "\n",
    "model = build_custom_cnn(n_freq_cnn=mel_bands, n_frames_cnn=sequence_frames,large_cnn=large_cnn)\n",
    "\n",
    "##### Inicializo\n",
    "model.layers[1].set_weights([np.ones_like(mean),np.zeros_like(mean),mean,scale])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = Adam(lr=learning_rate)\n",
    "\n",
    "if resume:\n",
    "    print('Loading best weights and resuming...')\n",
    "    weights_best_file = os.path.join(expfolder, 'weights_best.hdf5')\n",
    "    model.load_weights(weights_best_file)\n",
    "\n",
    "# Fit model\n",
    "print('\\nFitting model...')\n",
    "\n",
    "if resume:\n",
    "    f1s_best = resume_f1_best\n",
    "\n",
    "metrics_callback = MetricsCallback(x_val, y_val, 0, 0, os.path.join(expfolder, 'weights_best.hdf5'))\n",
    "#save_fig = SaveFigCallback(train_example,train_y_example,val_example,val_y_example,'./mels/')\n",
    "csv_logger = CSVLogger(os.path.join(expfolder, 'training.log'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=opt)\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=2*batch_size, #Borrar el 10!\n",
    "                            epochs=epochs, verbose=fit_verbose,\n",
    "                            validation_split=0.0,\n",
    "                            shuffle=True,\n",
    "                            #callbacks=[MyCallback(alpha, beta),metrics_callback,save_fig])\n",
    "                            callbacks=[metrics_callback,csv_logger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
