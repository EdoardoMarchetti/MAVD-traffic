{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "from mavd.model import build_custom_cnn\n",
    "from mavd.callbacks import MetricsCallback\n",
    "from mavd.data_generator import DataGenerator\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files parameters\n",
    "Nfiles = None\n",
    "resume = False\n",
    "load_subset = Nfiles\n",
    "\n",
    "# audio parameters\n",
    "sr = 22050\n",
    "sequence_time = 1.0\n",
    "sequence_hop_time = 1.0\n",
    "audio_hop = 512\n",
    "audio_win = 1024\n",
    "n_fft = 1024\n",
    "normalize_data = 'none' # para comparar loss con MST\n",
    "get_annotations = True\n",
    "mel_bands = 128\n",
    "htk = True\n",
    "normalize_energy = True\n",
    "\n",
    "# training\n",
    "learning_rate = 0.001\n",
    "epochs = 101\n",
    "batch_size = 64\n",
    "sed_early_stopping = 100\n",
    "epoch_limit = None\n",
    "fit_verbose = True\n",
    "fine_tuning = False\n",
    "\n",
    "#model\n",
    "large_cnn = True\n",
    "frames = True\n",
    "\n",
    "label_list = (['air_conditioner', 'car_horn', 'children_playing',\n",
    "               'dog_bark', 'drilling', 'engine_idling', 'gun_shot',\n",
    "               'jackhammer', 'siren', 'street_music'])  \n",
    "\n",
    " # Create output folders\n",
    "expfolder = '../exps/S-CNN_baseline/'\n",
    "\n",
    "audio_folder = '/data_ssd/users/pzinemanas/maestria/URBAN-SED/audio22050'\n",
    "label_folder='/data_ssd/users/pzinemanas/maestria/URBAN-SED/annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Founding scaler\n",
      "Making generators\n",
      "Getting data\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-22fae0b37c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Getting data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mtrain_example\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_mel_example\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_example\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MAVD-traffic/mavd/data_generator.py\u001b[0m in \u001b[0;36mreturn_random\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_IDs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_IDs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MAVD-traffic/mavd/data_generator.py\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, list_IDs_temp)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MAVD'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mevent_rolls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mindex_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "params = {'files_batch':20, 'path':audio_folder, 'sequence_time': sequence_time, \n",
    "          'sequence_hop_time':sequence_hop_time,'label_list':label_list,\n",
    "          'normalize_energy':normalize_energy,'audio_hop':audio_hop, 'audio_win':audio_win,\n",
    "          'n_fft':n_fft,'sr':sr,'mel_bands':mel_bands,'normalize':normalize_data, 'frames':frames,\n",
    "          'get_annotations':get_annotations, 'dataset': 'URBAN-SED'}\n",
    "\n",
    "sequence_frames = int(np.ceil(sequence_time*sr/audio_hop))\n",
    "\n",
    "# Datasets\n",
    "partition = {}# IDs\n",
    "labels = {}# Labels\n",
    "\n",
    "train_files = sorted(glob.glob(os.path.join(audio_folder,'train', '*.wav')))\n",
    "val_files = sorted(glob.glob(os.path.join(audio_folder,'validate', '*.wav')))\n",
    "\n",
    "if load_subset is not None:\n",
    "    train_files = train_files[:load_subset]\n",
    "    val_files = val_files[:load_subset]\n",
    "\n",
    "train_labels = {}\n",
    "train_mel = {}\n",
    "val_labels = {}\n",
    "val_mel = {}\n",
    "mel_basis = librosa.filters.mel(sr,n_fft,mel_bands,htk=True)\n",
    "print('Founding scaler')\n",
    "for n,id in enumerate(train_files):\n",
    "    labels[id] = os.path.join(label_folder, 'train',os.path.basename(id).replace('.wav','.txt'))\n",
    "    #train_mel[id]  = os.path.join(mel_folder, 'train',os.path.basename(id).replace('.wav','.npy.gz'))\n",
    "for id in val_files:\n",
    "    labels[id] = os.path.join(label_folder, 'validate',os.path.basename(id).replace('.wav','.txt'))\n",
    "\n",
    "params['train'] = True\n",
    "# Generators\n",
    "print('Making generators')\n",
    "training_generator = DataGenerator(train_files, labels, **params)\n",
    "scaler = training_generator.get_scaler()\n",
    "#print('scaler',scaler)\n",
    "\n",
    "params['scaler'] = scaler\n",
    "params['train'] = False\n",
    "params['sequence_hop_time'] = sequence_time\n",
    "\n",
    "validation_generator = DataGenerator(val_files, labels, **params)\n",
    "\n",
    "print('Getting data')\n",
    "\n",
    "train_example,_,train_mel_example,train_y_example = training_generator.return_random()\n",
    "_,_,val_example,val_y_example = validation_generator.return_random()\n",
    "\n",
    "_,_,x_val,y_val = validation_generator.return_all()\n",
    "_,_,x_train,y_train = training_generator.return_all()\n",
    "\n",
    "if not frames:    \n",
    "    x_train = np.transpose(x_train,(0,2,1))    \n",
    "    x_val = np.transpose(x_val,(0,2,1))  \n",
    "    val_example = np.transpose(val_example,(0,2,1))     \n",
    "\n",
    "\n",
    "print(x_train.shape)    \n",
    "print(x_val.shape)     \n",
    "\n",
    "print(x_val.shape,y_val[0].shape,y_val[1].shape)\n",
    "sequence_frames = x_val.shape[1]\n",
    "standard_scaler = training_generator.get_standard_scaler()\n",
    "\n",
    "mean= standard_scaler.mean_\n",
    "scale = standard_scaler.scale_\n",
    "\n",
    "# Build model\n",
    "\n",
    "print('\\nBuilding model...')\n",
    "\n",
    "sequence_samples = int(sequence_time*sr)\n",
    "\n",
    "model = build_custom_cnn(n_freq_cnn=mel_bands, n_frames_cnn=sequence_frames,large_cnn=large_cnn)\n",
    "\n",
    "##### Inicializo\n",
    "model.layers[1].set_weights([np.ones_like(mean),np.zeros_like(mean),mean,scale])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = Adam(lr=learning_rate)\n",
    "\n",
    "if resume:\n",
    "    print('Loading best weights and resuming...')\n",
    "    weights_best_file = os.path.join(expfolder, 'weights_best.hdf5')\n",
    "    model.load_weights(weights_best_file)\n",
    "\n",
    "# Fit model\n",
    "print('\\nFitting model...')\n",
    "\n",
    "if resume:\n",
    "    f1s_best = resume_f1_best\n",
    "\n",
    "metrics_callback = MetricsCallback(x_val, y_val, 0, 0, os.path.join(expfolder, 'weights_best.hdf5'))\n",
    "#save_fig = SaveFigCallback(train_example,train_y_example,val_example,val_y_example,'./mels/')\n",
    "csv_logger = CSVLogger(os.path.join(expfolder, 'training.log'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=opt)\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=2*batch_size, #Borrar el 10!\n",
    "                            epochs=epochs, verbose=fit_verbose,\n",
    "                            validation_split=0.0,\n",
    "                            shuffle=True,\n",
    "                            #callbacks=[MyCallback(alpha, beta),metrics_callback,save_fig])\n",
    "                            callbacks=[metrics_callback,csv_logger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
