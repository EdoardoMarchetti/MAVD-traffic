{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "from mavd.model import build_custom_cnn\n",
    "from mavd.data_generator_URBAN_SED import DataGenerator\n",
    "from mavd.callbacks import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pzinemanas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# files parameters\n",
    "Nfiles = None\n",
    "resume = False\n",
    "load_subset = Nfiles\n",
    "\n",
    "label_list = (['air_conditioner', 'car_horn', 'children_playing',\n",
    "               'dog_bark', 'drilling', 'engine_idling', 'gun_shot',\n",
    "               'jackhammer', 'siren', 'street_music'])  \n",
    "\n",
    " # Create output folders\n",
    "expfolder = '../exps/S-CNN_baseline/'\n",
    "\n",
    "from exps.S-CNN_baseline.params import *\n",
    "\n",
    "#param_path = os.path.join(expfolder,'params.py')\n",
    "#params = yaml.load(open(param_path))\n",
    "\n",
    "audio_folder = '/data_ssd/users/pzinemanas/maestria/URBAN-SED/audio22050'\n",
    "#feature_folder = '../../MedleyDB/22050'\n",
    "label_folder='/data_ssd/users/pzinemanas/maestria/URBAN-SED/annotations'\n",
    "\n",
    "alpha = 10**8 #REF del log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Founding scaler\n",
      "Making generators\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'htk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e29439e73b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Making generators'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtest_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m#scaler = training_generator.get_scaler()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#print('scaler',scaler)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'htk'"
     ]
    }
   ],
   "source": [
    "#params = {'files_batch':20, 'path':audio_folder, 'sequence_time': sequence_time, 'sequence_hop_time':sequence_hop_time,'label_list':label_list,'alpha': alpha,'normalize_energy':normalize_energy,\n",
    "    #      'audio_hop':audio_hop, 'audio_win':audio_win,'n_fft':n_fft,'sr':sr,'mel_bands':mel_bands,'normalize':normalize_data, 'frames':frames,'get_annotations':get_annotations}\n",
    "\n",
    "#params['path'] = audio_folder\n",
    "#params['label_list'] = label_list\n",
    "#sequence_frames = int(np.ceil(params['sequence_time']*params['sr']/params['audio_hop']))\n",
    "sequence_frames = int(np.ceil(sequence_time*sr/audio_hop))\n",
    "\n",
    "# Datasets\n",
    "partition = {}# IDs\n",
    "labels = {}# Labels\n",
    "\n",
    "test_files = sorted(glob.glob(os.path.join(audio_folder,'test', '*.wav')))\n",
    "val_files = sorted(glob.glob(os.path.join(audio_folder,'validate', '*.wav')))\n",
    "\n",
    "if load_subset is not None:\n",
    "    test_files = test_files[:load_subset]\n",
    "    val_files = val_files[:load_subset]\n",
    "\n",
    "test_labels = {}\n",
    "test_mel = {}\n",
    "val_labels = {}\n",
    "val_mel = {}\n",
    "print('Founding scaler')\n",
    "for n,id in enumerate(test_files):\n",
    "    labels[id] = os.path.join(label_folder, 'test',os.path.basename(id).replace('.wav','.txt'))\n",
    "    #train_mel[id]  = os.path.join(mel_folder, 'train',os.path.basename(id).replace('.wav','.npy.gz'))\n",
    "for id in val_files:\n",
    "    labels[id] = os.path.join(label_folder, 'validate',os.path.basename(id).replace('.wav','.txt'))\n",
    "\n",
    "params['train'] = False\n",
    "\n",
    "# Generators\n",
    "print('Making generators')\n",
    "test_generator = DataGenerator(test_files, labels, **params)\n",
    "#scaler = training_generator.get_scaler()\n",
    "#print('scaler',scaler)\n",
    "\n",
    "#params['scaler'] = scaler\n",
    "#params['train'] = False\n",
    "params['sequence_hop_time'] = sequence_time\n",
    "\n",
    "validation_generator = DataGenerator(val_files, labels, **params)\n",
    "\n",
    "print('Getting data')\n",
    "\n",
    "_,_,x_val,y_val = validation_generator.return_all()\n",
    "_,_,x_test,y_test = test_generator.return_all()\n",
    "\n",
    "print(x_val.shape, y_val.shape)\n",
    "\n",
    "sequence_frames = x_val.shape[1]\n",
    "\n",
    "# Build model\n",
    "\n",
    "print('\\nBuilding model...')\n",
    "\n",
    "sequence_samples = int(sequence_time*sr)\n",
    "\n",
    "model = build_custom_cnn(n_freq_cnn=mel_bands, n_frames_cnn=sequence_frames,large_cnn=large_cnn)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "weights_best_file = os.path.join(expfolder, 'weights_best.hdf5')\n",
    "model.load_weights(weights_best_file)\n",
    "\n",
    "# Fit model\n",
    "print('\\nTesting model...')\n",
    "\n",
    "y_test_predicted = model.predict(x_test)\n",
    "y_val_predicted = model.predict(x_val)\n",
    "\n",
    "#np.save('predict_proba.npy',y_val_predicted)\n",
    "#np.save('test_proba.npy',y_val)\n",
    "\n",
    "\n",
    "np.save(os.path.join(expfolder, 'y_test_predict.npy'),y_test_predicted)\n",
    "np.save(os.path.join(expfolder, 'y_test.npy'),y_test)\n",
    "\n",
    "print(y_test.shape)\n",
    "\n",
    "print(F1(y_test,y_test_predicted))\n",
    "print(ER(y_test,y_test_predicted))\n",
    "print(F1(y_val,y_val_predicted))\n",
    "print(ER(y_val,y_val_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
