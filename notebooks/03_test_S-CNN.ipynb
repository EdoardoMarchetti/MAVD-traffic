{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import sys\n",
    "#import yaml\n",
    "import pickle\n",
    "\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "from mavd.model import build_custom_cnn\n",
    "from mavd.data_generator_URBAN_SED import DataGenerator\n",
    "from mavd.callbacks import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files parameters\n",
    "Nfiles = None\n",
    "resume = False\n",
    "load_subset = Nfiles\n",
    "\n",
    "# audio parameters\n",
    "sr = 22050\n",
    "sequence_time = 1.0\n",
    "sequence_hop_time = 1.0\n",
    "audio_hop = 512\n",
    "audio_win = 1024\n",
    "n_fft = 1024\n",
    "normalize_data = 'none' # para comparar loss con MST\n",
    "get_annotations = True\n",
    "mel_bands = 128\n",
    "normalize_energy = True\n",
    "\n",
    "# training\n",
    "learning_rate = 0.001\n",
    "epochs = 101\n",
    "batch_size = 64\n",
    "sed_early_stopping = 100\n",
    "epoch_limit = None\n",
    "fit_verbose = True\n",
    "fine_tuning = False\n",
    "\n",
    "#model\n",
    "large_cnn = True\n",
    "frames = True\n",
    "\n",
    "label_list = (['air_conditioner', 'car_horn', 'children_playing',\n",
    "               'dog_bark', 'drilling', 'engine_idling', 'gun_shot',\n",
    "               'jackhammer', 'siren', 'street_music'])  \n",
    "\n",
    " # Create output folders\n",
    "expfolder = '../exps/S-CNN_baseline/'\n",
    "\n",
    "\n",
    "audio_folder = '/data_ssd/users/pzinemanas/maestria/URBAN-SED/audio22050'\n",
    "#feature_folder = '../../MedleyDB/22050'\n",
    "label_folder='/data_ssd/users/pzinemanas/maestria/URBAN-SED/annotations'\n",
    "\n",
    "alpha = 10**8 #REF del log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Founding scaler\n",
      "Making generators\n",
      "Getting data\n",
      "(20000, 44, 1024)\n",
      "(20000, 44, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 11:32:35.150956 139965999163136 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0829 11:32:35.160333 139965999163136 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0829 11:32:35.203613 139965999163136 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0829 11:32:35.221370 139965999163136 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0829 11:32:35.230349 139965999163136 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0829 11:32:35.239535 139965999163136 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 44, 128) (20000, 10)\n",
      "\n",
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 11:32:36.395885 139965999163136 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0829 11:32:36.636306 139965999163136 deprecation.py:506] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 44, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 128)           512       \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 44, 128, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 40, 124, 128)      3328      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 62, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 58, 128)       409728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 29, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 29, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 25, 128)        409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 25, 128)        512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,481,162\n",
      "Trainable params: 2,480,138\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "\n",
      "Testing model...\n",
      "(20000, 10)\n",
      "0.5678165528162241\n",
      "0.5271129960418391\n",
      "0.544811320128272\n",
      "0.542858229367856\n"
     ]
    }
   ],
   "source": [
    "params = {'files_batch':20, 'path':audio_folder, 'sequence_time': sequence_time, 'sequence_hop_time':sequence_hop_time,'label_list':label_list,'alpha': alpha,'normalize_energy':normalize_energy,\n",
    "          'audio_hop':audio_hop, 'audio_win':audio_win,'n_fft':n_fft,'sr':sr,'mel_bands':mel_bands,'normalize':normalize_data, 'frames':frames,'get_annotations':get_annotations}\n",
    "\n",
    "#params['path'] = audio_folder\n",
    "#params['label_list'] = label_list\n",
    "#sequence_frames = int(np.ceil(params['sequence_time']*params['sr']/params['audio_hop']))\n",
    "sequence_frames = int(np.ceil(sequence_time*sr/audio_hop))\n",
    "\n",
    "# Datasets\n",
    "partition = {}# IDs\n",
    "labels = {}# Labels\n",
    "\n",
    "test_files = sorted(glob.glob(os.path.join(audio_folder,'test', '*.wav')))\n",
    "val_files = sorted(glob.glob(os.path.join(audio_folder,'validate', '*.wav')))\n",
    "\n",
    "if load_subset is not None:\n",
    "    test_files = test_files[:load_subset]\n",
    "    val_files = val_files[:load_subset]\n",
    "\n",
    "test_labels = {}\n",
    "test_mel = {}\n",
    "val_labels = {}\n",
    "val_mel = {}\n",
    "print('Founding scaler')\n",
    "for n,id in enumerate(test_files):\n",
    "    labels[id] = os.path.join(label_folder, 'test',os.path.basename(id).replace('.wav','.txt'))\n",
    "    #train_mel[id]  = os.path.join(mel_folder, 'train',os.path.basename(id).replace('.wav','.npy.gz'))\n",
    "for id in val_files:\n",
    "    labels[id] = os.path.join(label_folder, 'validate',os.path.basename(id).replace('.wav','.txt'))\n",
    "\n",
    "params['train'] = False\n",
    "\n",
    "# Generators\n",
    "print('Making generators')\n",
    "test_generator = DataGenerator(test_files, labels, **params)\n",
    "#scaler = training_generator.get_scaler()\n",
    "#print('scaler',scaler)\n",
    "\n",
    "#params['scaler'] = scaler\n",
    "#params['train'] = False\n",
    "params['sequence_hop_time'] = sequence_time\n",
    "\n",
    "validation_generator = DataGenerator(val_files, labels, **params)\n",
    "\n",
    "print('Getting data')\n",
    "\n",
    "_,_,x_val,y_val = validation_generator.return_all()\n",
    "_,_,x_test,y_test = test_generator.return_all()\n",
    "\n",
    "print(x_val.shape, y_val.shape)\n",
    "\n",
    "sequence_frames = x_val.shape[1]\n",
    "\n",
    "# Build model\n",
    "\n",
    "print('\\nBuilding model...')\n",
    "\n",
    "sequence_samples = int(sequence_time*sr)\n",
    "\n",
    "model = build_custom_cnn(n_freq_cnn=mel_bands, n_frames_cnn=sequence_frames,large_cnn=large_cnn)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "weights_best_file = os.path.join(expfolder, 'weights_best.hdf5')\n",
    "model.load_weights(weights_best_file)\n",
    "\n",
    "# Fit model\n",
    "print('\\nTesting model...')\n",
    "\n",
    "y_test_predicted = model.predict(x_test)\n",
    "y_val_predicted = model.predict(x_val)\n",
    "\n",
    "#np.save('predict_proba.npy',y_val_predicted)\n",
    "#np.save('test_proba.npy',y_val)\n",
    "\n",
    "\n",
    "#np.save(os.path.join(expfolder, 'y_test_predict.npy'),y_test_predicted)\n",
    "#np.save(os.path.join(expfolder, 'y_test.npy'),y_test)\n",
    "\n",
    "data = {'val': {'y': y_val, 'predicted': y_val_predicted}, 'test': {'y': y_test, 'predicted': y_test_predicted}}\n",
    "filename = os.path.join(expfolder,'results.pickle')\n",
    "pickle.dump(data, open(filename, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(y_test.shape)\n",
    "\n",
    "print(F1(y_test,y_test_predicted))\n",
    "print(ER(y_test,y_test_predicted))\n",
    "print(F1(y_val,y_val_predicted))\n",
    "print(ER(y_val,y_val_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
